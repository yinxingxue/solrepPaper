\section{Related Work}\label{sec:related}

\noindent\textbf{The Optimal Feature Selection Problem.}
White \emph{et al.}~\cite{DBLP:journals/jss/WhiteDS09} first modeled the feature selection problem as a Multidimensional Multi-Choice Knapsack Problem (MMKP), and applied Filtered Cartesian Flattening (FCF) to derive an optimal feature configuration subject to resource constraints.
%The existing works \cite{DBLP:journals/jss/GuoWWLW11,DBLP:conf/icse/SayyadMA13,conf/cmsbse/SayyadMA13,DBLP:dblp_conf/kbse/SayyadIMA13, DBLP:conf/issta/TanXCSLD15} have adopted evolutionary algorithms (EAs) for feature selection with resource constraints and product generation based on the value of user preferences, respectively.
Guo \emph{et al.}  \cite{DBLP:journals/jss/GuoWWLW11} first proposed a genetic algorithm (GA) approach to tackle this problem. In \cite{DBLP:journals/jss/GuoWWLW11}, a repair operator is used to fix each candidate solution, and make it comply with the feature model during evolution. %This approach might be non-terminating, and furthermore, it does not take advantage of the automatic correction  that brought by the GA.
One limitation of \cite{DBLP:journals/jss/GuoWWLW11} lies in aggregating all objectives into a single fitness function with different weights. %This only gives users a solution specific to the weights used in the objective formula.

To address the objective aggregation issue, Sayyad \emph{et al.}~\cite{DBLP:conf/icse/SayyadMA13,conf/cmsbse/SayyadMA13} first proposed to apply various MOEAs, and a range of optimal solutions (a.k.a., a Pareto front) is returned to the user as a result. As reported, IBEA \cite{DBLP:conf/ppsn/ZitzlerK04} yields the best results among the seven tested EAs in terms of time, correctness and satisfaction to user preferences. In \cite{DBLP:dblp_conf/kbse/SayyadIMA13}, they further used static method to prune features before execution of IBEA for reducing search space. They also introduced a ``seeding method\rq\rq{} by pre-computing a correct solution, which was later implanted the initial population of IBEA. Along this line, Tan \emph{et al.} \cite{DBLP:conf/issta/TanXCSLD15} improved these previous studies by using a novel feedback-directed mechanism to existing EAs. %In their approach, the feature model is first preprocessed based on SAT solving to remove the prunable features, before the execution of an EA. %We have shown that we always prune more features compared to the pruning method in~\cite{DBLP:dblp_conf/kbse/SayyadIMA13}.
%During evolution, the violated constraints would be analyzed and analyzed results are used as feedback to guide evolutionary operators (i.e., crossover and mutation) for producing correct offsprings. %for the next round. This feedback-directed mechanism is mainly used to improve the correctness of offsprings.
Similarly, to improve the correctness, Hierons \emph{et al.} \cite{DBLP:journals/tosem/HieronsLLSZ16} proposed the $1+n$ approach that prioritizes the number of failed constraints and considers the correctness objective first.
%Our evaluation has shown that our method produces more promising offsprings (that have fewer violated constraints), which has led to faster convergence and resulted in more valid solutions in a significantly shorter amount of time.
Recently, IBEA (including its variants) is integrated with other techniques for achieving better results.  Henard \emph{et al.}~\cite{DBLP:conf/icse/HenardPHT15}
integrated IBEA with constraint solving. They permuted different SAT parameters to maximize the diversity of SAT solutions in a cheap way by calling SAT solver hundreds of times. %The merit is that the fixing of incorrect offspring of IBEA population via SAT solutions is done during evolution.
Xue \emph{et al.}~\cite{DBLP:journals/asc/XueZT0CC016} integrated IBEA with differential evolution (DE) for achieving both correctness and diversity of solutions. % Their method, named IBED, is a dual-population EA, where two populations are evolved with two different types of EA operators, i.e., IBEA operators and DE operators.

\vspace{0.5mm}
\noindent\textbf{MOO and SBSE.}
Apart from the above problem, MEOAs have exhibited the effectiveness in solving some earlier SBSE problems~\cite{DBLP:journals/csur/HarmanMZ12}. For example,  multi-objective planning for software project overtime is the SBSE problem solved by a variant of NSGAII \cite{DBLP:conf/icse/FerrucciHRS13}. Besides, the problem of bi-objective software effort estimation is also addressed by NSGAII~\cite{DBLP:conf/icse/SarroPH16}.
 In software refactoring, multi-objective refactoring step recommendation via NSGAII helps to ensure the semantic coherence of refactored program~\cite{DBLP:journals/ese/MkaouerKCHD17}. Last, a branch of MOO studies is on software test suite selection, minimization and prioritization~\cite{DBLP:conf/issta/YooH07}\cite{DBLP:journals/tse/MarchettoIASS16}.
NSGAII, which is used in aforementioned studies, is suitable  for  more  spread  out solutions  and  absolute domination. Hence, NSGAII works well if the solution space is not highly-constrained and diversity can help find more solutions. However, for the optimal feature selection, the preference of diversity (using NSGAII) may bring more incorrect solutions (since correct solutions may be concentrated in certain areas of  the solution space). To assure this, IBEA is advocated~\cite{DBLP:conf/icse/SayyadMA13}\cite{conf/cmsbse/SayyadMA13}. %IBEA is also combined with DE to achieve both correctness and diversity~\cite{DBLP:journals/asc/XueZT0CC016}.

%In \cite{DBLP:journals/infsof/HarmanJ01}, Harman \emph{et al.} proposed the term Search-Based Software Engineering (SBSE), and reported that the surveyed and proposed optimization techniques for SE problems by 2001 were all single-objective based. Seeing the potential of using multi-objective optimization, Harman \cite{DBLP:conf/icse/Harman07} discussed about the possible usage of the meta-heuristic search techniques such as: simulated annealing and genetic algorithm. Harman considered it insensible combination of  multiple metrics into an aggregate fitness in the way of assigning coefficients, and further suggested to use Pareto optimality rather than aggregate fitness.

\vspace{0.5mm}
\noindent\textbf{OR and SBSE.} IP has been used for the instantiation of products --- the valid product feature selection problem~\cite{DBLP:conf/splc/Broek10}. In~\cite{DBLP:conf/splc/Broek10}, only one single objective is considered, not addressing MOO via IP. Earlier than this study, requirement interdependencies were resolved via IP\cite{DBLP:journals/re/Carlshamre02}.
Then, flexible release planning was solved by IP~\cite{DBLP:conf/caise/AkkerBDV05}.
Subsequently, requirements selection and scheduling for the release planning were integrated and optimized by IP to cater for budgetary constraints  \cite{DBLP:conf/refsq/LiABD07}. Further,  IP was combined with computational intelligence and human negotiation to address conflicting objectives \cite{DBLP:journals/software/RuheS05}.
Recently, IP is not widely used due to its scalability issues and strict limitation on the application. Meanwhile, due to the emergence of MOO problems in SBSE, MOEAs  become the default method.

 %In 2009, Harman \emph{et al.}~\cite{tr:sesw} reported that MEOAs had been deployed to attain multi-objective optimization (especially two objectives), and the mainly used techniques were NSGA-II and SPEA2. By them, few studies had examined the performance and suitability of the commonly used MEOAs on more than three-objective optimization. In 2010, Bowman \emph{et al.}~\cite{DBLP:journals/tse/BowmanBL10} solved class responsibility assignment problem by applying five-objective optimization techniques on UML model analysis. They reported that SPEA2 can generally attain better results than RMHC1 and RMHC2. Recently, Sayyad \emph{et al.}~\cite{conf/raise/SabouriK11} found that among the existing application of MEOAs, the population based algorithm like NSGA-II was widely chosen for optimization of two or three objectives. Meanwhile, the comprehensive discussion and comparison of the suitability of different MEOAs are absent.
\vspace{-2mm}
